{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "import os\n",
    "from typing import List, Optional, Set, Tuple\n",
    "\n",
    "import regex\n",
    "\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'channel_name': 'sodapoppin',\n",
      " 'chat_message': 'ante*',\n",
      " 'is_toxic': False,\n",
      " 'preprocessed_chat_message': 'ante',\n",
      " 'timestamp': '2023-09-02T00:00:01.867916',\n",
      " 'username': 'blakelol',\n",
      " 'vw_toxicity_score': 0.538338}\n"
     ]
    }
   ],
   "source": [
    "with open(\"../chat_2023-09-03_10-32.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "    pprint(data[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# Copyright (c) Meta Platforms, Inc. and affiliates\n",
    "# All rights reserved.\n",
    "# \n",
    "# This source code is licensed under the license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "\n",
    "\n",
    "from dataset import DatasetLine\n",
    "from base import Filter, FilteringCounts\n",
    "from text_normalizer import replace_unicode_punct\n",
    "\n",
    "# Class to handle toxic word lists\n",
    "class ToxicityList:\n",
    "    \"\"\"A toxicity list is a list of toxic token sequences.\"\"\"\n",
    "\n",
    "    def __init__(self, word_list_paths: List[str]):\n",
    "        # Regular expression to split on punctuation, symbols, and Han characters\n",
    "        self._split = regex.compile(r\"(\\p{P}|\\p{S}|\\p{Han})\")\n",
    "        \n",
    "        # Set to store tokenized toxic items\n",
    "        self.toxicity: Set[str] = set()\n",
    "        \n",
    "        # Load and tokenize toxic items from provided word list paths\n",
    "        for path in word_list_paths:\n",
    "            with open(path, \"rt\") as fin:\n",
    "                for line in fin:\n",
    "                    line = line.strip()\n",
    "                    tokenized = self._tokenize(line)\n",
    "                    self.toxicity.add(tokenized)\n",
    "                    self.toxicity.add(tokenized.lower())\n",
    "\n",
    "    def _tokenize(self, s: str):\n",
    "        \"\"\"Tokenize a string for toxicity detection.\"\"\"\n",
    "        # Replace special unicode punctuations\n",
    "        s = replace_unicode_punct(s.strip())\n",
    "        # Split based on regular expression defined earlier\n",
    "        tok = self._split.sub(r\" \\1 \", s)\n",
    "        # Collapse multiple spaces into one\n",
    "        tok = \" \".join(tok.split())\n",
    "        # Add spaces before and after the tokenized string\n",
    "        # Helps in substring matching without false positives due to partial matches\n",
    "        return \" \" + tok + \" \"\n",
    "\n",
    "    def toxicity_count(self, s: str):\n",
    "        \"\"\"Return count of toxic items in a given string.\"\"\"\n",
    "        tokenized = self._tokenize(replace_unicode_punct(s))\n",
    "        regular = sum(1 for t in self.toxicity if t in tokenized)\n",
    "        lowercased = sum(1 for t in self.toxicity if t in tokenized.lower())\n",
    "        return max(regular, lowercased)\n",
    "\n",
    "# New class to hold the dataset line and its toxicity label\n",
    "class LabeledDatasetLine(DatasetLine):\n",
    "    def __init__(self, src: str, tgt: Optional[str], is_toxic: bool):\n",
    "        super().__init__(src, tgt)\n",
    "        self.is_toxic = is_toxic\n",
    "\n",
    "# Class to filter dataset lines based on their toxicity\n",
    "class ToxicityFilter(Filter):\n",
    "    # Initialization of filter with paths, thresholds, and languages\n",
    "    def __init__(\n",
    "        self,\n",
    "        twl_path_template: str,\n",
    "        eng_porn_twl_path: Optional[str],\n",
    "        max_toxicity: Optional[int],\n",
    "        max_toxicity_difference: Optional[int],\n",
    "        src_lang: str,\n",
    "        tgt_lang: Optional[str],\n",
    "    ):\n",
    "        self.max_toxicity = max_toxicity\n",
    "        self.max_toxicity_difference = max_toxicity_difference\n",
    "        self.tgt_toxicity_list: Optional[ToxicityList] = None\n",
    "        self.src_toxicity_list: Optional[ToxicityList] = None\n",
    "\n",
    "        # Load source language's toxic list\n",
    "        src_paths = []\n",
    "        src_twl_path = twl_path_template.format(lang=src_lang)\n",
    "        if os.path.isfile(src_twl_path):\n",
    "            src_paths.append(src_twl_path)\n",
    "        # Concatenate with the English list (if provided)\n",
    "        if eng_porn_twl_path is not None:\n",
    "            src_paths.append(eng_porn_twl_path)\n",
    "        if src_paths:\n",
    "            self.src_toxicity_list = ToxicityList(src_paths)\n",
    "\n",
    "        # Load target language's toxic list\n",
    "        tgt_paths = []\n",
    "        if tgt_lang is not None:\n",
    "            tgt_twl_path = twl_path_template.format(lang=tgt_lang)\n",
    "            if os.path.isfile(tgt_twl_path):\n",
    "                tgt_paths.append(tgt_twl_path)\n",
    "        # Concatenate with the English list (if provided)\n",
    "        if eng_porn_twl_path is not None:\n",
    "            tgt_paths.append(eng_porn_twl_path)\n",
    "        if tgt_paths:\n",
    "            self.tgt_toxicity_list = ToxicityList(tgt_paths)\n",
    "\n",
    "    def filter_line(self, line: DatasetLine, counts: FilteringCounts) -> LabeledDatasetLine:\n",
    "        \"\"\"Check if line's source and target are toxic and return labeled line.\"\"\"\n",
    "        is_src_toxic, is_tgt_toxic = False, False\n",
    "        \n",
    "        # Check toxicity in source text\n",
    "        if self.src_toxicity_list is not None:\n",
    "            src_toxicity = self.src_toxicity_list.toxicity_count(line.src)\n",
    "            if self.max_toxicity is not None and src_toxicity > self.max_toxicity:\n",
    "                counts.max_toxicity += 1\n",
    "                is_src_toxic = True\n",
    "\n",
    "        # Check toxicity in target text\n",
    "        if line.tgt is not None and self.tgt_toxicity_list is not None:\n",
    "            tgt_toxicity = self.tgt_toxicity_list.toxicity_count(line.tgt)\n",
    "            if self.max_toxicity is not None and tgt_toxicity > self.max_toxicity:\n",
    "                counts.max_toxicity += 1\n",
    "                is_tgt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thcvortex   5 minutes of ads!?!?! WHAT THE FUCK TWITCH\n",
      "default_guy77   @yung_gab_ sodaNo , he is da slut sodaSmirk\n",
      "tiodacombi   yea stfu chat\n",
      "sovietchina1   he's fucking trolling OMEGALUL\n",
      "aquaberrybackfist   holy shit\n",
      "paleblueboink   Dumbass head dent BALD\n",
      "admiral_nugget   run you fools!\n",
      "vikitorusss   pepeMeltdown FUCKING RUN\n",
      "skool_   what a shit show\n",
      "volkeb   FUCK THEM UP\n",
      "krottos   wtf is thos trol tank doing\n",
      "k3lw11   cant even 1v1 a ranger this dumb ass lacari\n",
      "dayzisgarbage   did lacari fuck up again\n",
      "raceoplasma   They both sneeze weird wtf\n",
      "tunacan_man   oh shit\n",
      "og_plumwick   holy fuck its a cycle man INSANECAT\n",
      "halfaxan   Just get a high dmg weapon and a shitty dagger\n",
      "the_mrx_   free shit hmm\n",
      "lacari   im so fucking BAD\n",
      "lacari   FUCKL\n",
      "crazytan_01   @Lacari fuck you, i'm addicted to holocure and its all your fault ReallyMad\n",
      "gayforcandy   that is the stash of a fucking battered man\n",
      "pattiiiiiiii   so much troll cum\n",
      "femboyelect   benjyvrSip cum\n",
      "aglassofbourbon   LookUp wtf\n",
      "dudeihateyousomuch   i'd drink the troll cum\n",
      "pale_al   you know whats great about chat is i can say ill drink all the cum. cum cum cum cum.\n",
      "captainuhhredemption   Man, am I horny\n",
      "frenchbussybestbussy   I'm horny too, down to fuck dude ?\n",
      "bowazanda   any hot dudes wanna fuck or what?\n",
      "captainuhhredemption   Sodomy chat?\n",
      "groinsalami   nobody cares how horny you guys are UHMM\n",
      "pale_al   piss cum shit ass tiddy fuck\n",
      "groinsalami   @captainuhhredemption, indeed, go be horny in dms\n",
      "hardstileraver   Jackass lac\n",
      "pale_al   one guyd by an idiot like me LULW\n",
      "malarchyy   FUCKING POTHEADS\n",
      "mauwii87   313 fuk freewlrld\n",
      "k3lw11   grown ass man\n",
      "churchmilfs   UHM ddlg shit\n",
      "supr3m3prim3   DUDE STFU LACARI\n",
      "bulletparry   DIESOFCRINGE grown ass man\n",
      "crazytan_01   dude shut the fuck up\n",
      "k3lw11   DIESOFCRINGE 30 year old grown ass man\n",
      "thesnoopydog   wtf is this please\n",
      "hideonpupusas   grown ass men buhing in chat\n",
      "locusquo   fuck those spiders\n",
      "1swagkat   wtf Spoogers\n",
      "tropicalshark   i LOVE pussy\n",
      "gayforcandy   they poop\n",
      "bulletparry   WICKED fucking shutterstock image cats will never have power\n",
      "mumbojumbogumbo   absolute dog shit stats\n",
      "the_mrx_   wtf is physical healing?\n",
      "gigatoadsageofhell   DICKHEAD OMEGALUL2\n",
      "paleblueboink   Douchebag\n",
      "javich14   Jackass douchebag\n",
      "tranpellets   Wtf Lacari, be nice\n",
      "nitefallin   @paleysium Unless your shit is really good or your underselling your shit no LUL\n",
      "bogusny   @GroinSalami, yeah i'd rather watch that shit probably\n",
      "bulletparry   GIGACHAD he's not the poop barb like you lac\n",
      "hideonpupusas   vei is faded than a hoe\n",
      "heinousanus95   Lacs morale is dogshit right now. Poor guy\n",
      "huntakilla   Willy Wanker HUH\n",
      "hede888   TwaT\n",
      "nightabsm   it does sound like an abusive foster parent or some shit OMEGALUL\n",
      "jadespherem   uuh hobbit ass name\n",
      "kelemvoruber   lacari cant loot anything big? my cock woul be left behind SadChamp\n",
      "cuff_d   @kelemvoruber u want lac to take ur dick?\n",
      "soap_v   OH SHIT\n",
      "heinousanus95   @bonash people with crhonic pain jackass\n",
      "splyntr_   OH FUCK\n",
      "nobanarino   veiD jackass\n",
      "iduckbro   Pointless wtf man\n",
      "imbaelfire   take the booty\n"
     ]
    }
   ],
   "source": [
    "# print toxicities of a first chat message\n",
    "\n",
    "toxicity_list = ToxicityList([\"../eng_Latn_twl.txt\"])\n",
    "toxic_list = []\n",
    "\n",
    "for line in data:\n",
    "    # print(line['chat_message'])    \n",
    "    # print toxicity of a first chat message\n",
    "    \n",
    "    if toxicity_list.toxicity_count(line['chat_message']) > 0:\n",
    "        print(line[\"username\"], \" \", line['chat_message'])\n",
    "        toxic_list.append(line)\n",
    "  \n",
    "# print(len(toxic_list), toxic_list )       \n",
    "# export above to a json file\n",
    "filename = 'toxic_chat_' + datetime.now().strftime(\"%Y-%m-%d_%H-%M\") + '.json'\n",
    "with open(filename, 'w') as outfile:\n",
    "    json.dump(toxic_list, outfile, indent=4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(data[0]['chats']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
